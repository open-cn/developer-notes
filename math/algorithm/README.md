## algorithm

“算法”一词最早出现在《周髀算经》这本书中，代指阿拉伯数字的运算规则（例如 1+1=2），对应的英文单词是“algorism”。随着计算机和编程语言的快速发展，“算法”被赋予了新的含义，代指解决问题的过程（步骤、方案），对应的英文单词变成了“algorithm”。

算法规定了解决某个问题的具体步骤，先做什么、再做什么、最后做什么，只要依次完成这些步骤，问题就可以得到解决。

算法的种类有很多。常用的算法包括动态规划算法、分治算法、贪心算法、排序算法、查找算法等，每种算法用来解决某一类实际问题。

算法和问题之间并不是简单的“一对一”关系：

- 一个算法解决的是具有共性的一类问题，例如排序算法，任何需要对数据进行排序的问题都可以用此算法解决；
- 一个问题往往对应有多种算法，虽然它们最终都可以解决问题，但有的算法效率高，有的效率低，需要我们具备挑选“好”算法的能力。

挑选算法时，主要考虑以下两方面因素：

- 执行效率：根据算法所编写的程序，执行时间越短，执行效率就越高；
- 占用的内存空间：不同算法编写出的程序，运行时占用的内存空间也不相同。如果实际场景中仅能使用少量的内存空间，就应该优先选择占用空间最少的算法。

当问题对应的算法数量较少时（比如 2、3 种），我们可以编写出各个算法对应的程序，逐个在机器上运行，记录它们各自的执行时间和占用内存空间的大小，最终挑选出“最好”的算法。如果问题对应的算法数量有很多（比如 10 种，20 种），先前的挑选方式将不再适用，因为将各个算法一一编写成程序的工作量是巨大的，得不偿失。

实际开发中，我们往往采用“预先估值”的方法挑选算法。具体来讲，就是分析各个算法的实现过程（步骤），估算出它们各自的运行时间和占用的内存空间，进而挑选出“最好”的算法。用“预先估算”方式挑选算法时，我们习惯用时间复杂度表示一个算法的运行时间，用空间复杂度表示算法占用存储空间的大小。

算法提供的仅仅是解决问题的思路，真正解决问题的是我们编写的程序。算法和程序之间的关系可以这样理解，根据算法提供的解题思路，程序员编写出计算机能识别的程序代码，交由计算机执行，从而解决问题。编程语言的种类有很多，比如 Java、C/C++、Python 等，我们学习的算法适用于所有的编程语言。

### 伪代码描述算法

伪代码是一种介于自然语言和编程语言之间，专门用来描述算法的语言。

用自然语言描述算法，其实就是口述算法的各个步骤。由于每个人的语气口吻、表达方法各不相同，很可能出现用词不当、语言表述不清等问题。

举个简单的例子，设计一种算法，计算 n! 并输出最终结果。

如下用自然语言描述了一种解决此问题的算法：

- 第 1 步：接收 n 的值；
- 第 2 步：计算从 1 到 n 的乘积，并赋值给 p；
- 第 3 步：输出 p 的值。

使用伪代码描述算法，可以彻底避免自然语言存在的问题。例如，上面算法对应的伪代码是：
```Pseudocode
输入 n                 // 接收 n 的值
p <- 1                 // p 的初值置为 1
for i <- 1 to n：    // i 的值从 1 到 n，每次将 p*i 的值赋值给 p
    p <- p * i      
Print p                // 输出 p 的值
```

编程语言，其实就是指有严格的语法规定、能被计算机识别的语言，例如 Java、Python、C/C++ 等，它们都是编程语言。

伪代码并不是一门具体的编程语言，它没有严格的语法规定，也无法在计算机上运行。和编程语言相比，用伪代码描述算法最大的优势是：不需要考虑太多语法细节，大大降低了使用门槛。

### 时间复杂度
时间复杂度用于表示算法的执行时间。

以求 n! 的算法为例：
```
输入 n                 // 接收 n 的值
p <- 1                 // p 的初值置为 1
for i <- 1 to n：    // i 的值从 1 一直到 n
    p <- p * i        // 将 p*i 的值赋值给 p
Print p                // 输出 p 的值
```

计算它的时间复杂度，只需经历以下几个步骤：

1. 统计算法中各个步骤的执行次数

整个算法中共有 5 行伪指令，它们各自的执行次数分别是：
```
输入 n                 // 执行 1 次
p <- 1                 // 执行 1 次
for i <- 1 to n：    // i 的值从 1 遍历到 n，当 i 的值为 n+1 的时候退出循环，总共执行 n+1 次
    p <- p * i         // i 从 1 到 n 的过程，共执行 n 次
Print p                 // 执行 1 次
```
统计算法中所有伪指令执行的总次数，结果为$2n+4$。显然，$2n+4$不是一个固定值，整个表达式值的大小取决于 n 的值。$2n+4$可以直接作为算法执行时间的估值，也可以对它进行简化，用规范的形式表示算法的运行时间。

2. 简化算法的执行次数

通过统计各个算法中每条伪指令的执行次数，每个算法的运行时间都可以用类似$2n+4$、$3n^2+4n+5$这样的表达式表示。这就产生一个问题，如何比较各个表达式的大小呢？

首先，我们可以尝试对每个表达式进行简化，简化方法是：假设表达式中变量的值无限大时，去除掉那些对表达式结果影响较小的项。以$3n^2+4n+5$为例，简化过程为：

- 当 n 无限大时，$3n^2+4n$与$3n^2+4n+5$的值非常接近，是否加 5 对表达式的值影响不大，因此表达式可以简化为$3n^2+4n$；
- 当 n 无限大时，$3*n^2$的值要远远大于$4n$的值，它们之间类似于 10000 和 1 之间的关系，因此是否加$4n$对表达式最终的值影响不大，整个表达式可以简化为$3n^2$；
- 当 n 无限大时，$n^2$的值已经超级大，是否乘 3 对最终结果影响不大，整个表达式可以简化为$n^2$。

简化表达式的过程可以总结为：

- 去掉表达式中所有的加法常数项，$3n^2+4n+5$中的 5 就是加法常数项；
- 只保留表达式中变量指数最大的项，$3n^2+4n$中 n 的最大指数为 2，所以只保留$3n^2$；
- 去掉常数系数，$3n^2$中的 3 就是$n^2$的常数系数。

基于“n 值无限大”的思想，$3n^2+4n+5$最终可以简化为$n^2$。无论多么复杂的表达式，都可以采用这种方式进行简化。

3. 大O记法表示时间复杂度

除了用 n 外，一些人还可能会用 a、b、c 等字符作为表达式中的变量。为此，人们逐渐达成了一种共识，即都用 n 作为表达式中的变量，并采用大 O 记法表示算法的执行时间。

采用大 O 记法表示算法的执行时间，直接套用如下的格式即可：
`O(频度)`

频度指的就是简化后的表达式。

采用大 O 记法，$2n+4$可以用$O(n)$表示，$3n^2+4n+5$ 可以用$O(n^2)$表示。注意，如果一个算法对应的表达式中没有变量（比如 10，100 等），则用$O(1)$表示算法的执行时间。

如果一个算法的执行时间最终估算为$O(n)$，那么该算法的时间复杂度就是$O(n)$。如下列举了常用的几种时间复杂度以及它们之间的大小关系：
$O(1)< O(\log{n}) < O(n) < O(n^2) < O(n^3) < O(2^n)$。

$O(1)$是最小的，对应的算法的执行时间最短，执行效率最高。


### 空间复杂度
空间复杂度衡量的是算法执行过程占用的内存空间的大小。

比较多个算法占用的内存大小，本质上比较的是各个算法执行过程中额外申请的内存空间的大小。举个简单的例子：

```
输入 n
A[i...n] <- {1...n}    // 额外申请 n 个空间
```
根据 n 的值，算法执行时需要申请 n 个整数的内存空间，n 的值越大，额外申请的内存空间就越多。

与时间复杂度的表示方法一样，空间复杂度也采用大 O 记法表示。算法空间复杂度的估算方法是：

- 如果算法中额外申请的内存空间不受用户输入值的影响（是一个固定值），那么该算法的空间复杂度用 O(1) 表示；
- 如果随着输入值 n 的增大，算法申请的存储空间成线性增长，则程序的空间复杂度用 O(n) 表示;
- 如果随着输入值 n 的增大，程序申请的存储空间成 $n^2$ 关系增长，则程序的空间复杂度用 $O(n^2)$ 表示；
- 如果随着输入值 n 的增大，程序申请的存储空间成 $n^3$ 关系增长，则程序的空间复杂度用 $O(n^3)$ 表示；


### 递归算法

编程语言中，我们习惯将函数（方法）调用自身的过程称为递归，调用自身的函数称为递归函数，用递归方式解决问题的算法称为递归算法。

当发生递归调用时，多数编程语言都使用栈结构保存调用者的状态信息，包括暂停时局部变量的值、寄存器中保存的数据等等。

除了求 n! 外，递归算法还可以解决斐波那契数列问题，很多算法也都需要借助递归实现，例如分治算法、回溯算法等


### 斐波那契数列

公元 1202 年，意大利数学家莱昂纳多·斐波那契提出了具备以下特征的数列：

- 前两个数的值分别为 0 、1 或者 1、1；
- 从第 3 个数字开始，它的值是前两个数字的和；

为了纪念他，人们将满足以上两个特征的数列称为斐波那契数列。

`1 1 2 3 5 8 13 21 34`

```
fibonacci(n):       // n 表示求数列中第 n 个位置上的数的值
    if n == 1:        // 设置结束递归的限制条件
        return 1
    if n == 2:        // 设置结束递归的限制条件
        return 1
    return fibonacci(n-1) + fibonacci(n-2)    // F(n) = F(n-1) + F(n-2)
```
递归实现斐波那契数列的执行效率是很低的，这与递归的底层实现机制有关。

以非递归方式实现的 fibonacci() 函数，调用一次就可以生成长度为 n 的斐波那契数列

```
//连续输出长度为 n 的斐波那契数列
fibonacci(n):
    num1 <- 1    // 设置 num1 的初值为 1
    num2 <- 1    // 设置 num2 的初值为 1
    for i <- 1 to n:
        Print(num1)              // 输出 num1 的值
        nextNum <- num1 + num2   // 将 num1+num2 的值赋值给 nextNum
        num1 <- num2             // num2 的值赋值给 num1
        num2 <- nextNum          // nextNum 的值赋值给 num2
```

### 分治算法

分治算法中，“分治”即“分而治之”的意思。分治算法解决问题的思路是：先将整个问题拆分成多个相互独立且数据量更少的小问题，通过逐一解决这些简单的小问题，最终找到解决整个问题的方案。

所谓问题间相互独立，简单理解就是每个问题都可以单独处理，不存在“谁先处理，谁后处理”的次序问题。

分治算法解决问题的过程需要经历 3 个阶段，分别是：

- 分：将整个问题划分成多个相对独立、涉及数据量更少的小问题，有些小问题还可以划分成很多更小的问题，直至每个问题都不可再分；
- 治：逐个解决所有的小问题；
- 合并：将所有小问题的解决方案合并到一起，找到解决整个问题的方案。

分治算法解决的经典问题有很多，包括汉诺塔问题、寻找数列中最大值和最小值的问题等等。

分治算法还和其它算法搭配使用，比如二分查找算法、归并排序算法、快速排序算法等

分治算法的弊端也很明显，该算法经常和递归算法搭配使用，整个解决问题的过程会耗费较多的时间和内存空间，严重时还可能导致程序运行崩溃。


#### 找数组的最大值和最小值

普通算法
```
输入 num[1...n]              // 输入 n 个数字
max <- num[1]                // 将第 1 个数字赋值给 max（表示最大值）
min <- num[1]                // 将第 1 个数字赋值给 min（表示最小值）
for i <- 2 to n:             // 从第 2 个数字开始遍历
    if num[i] > max:         // 如果 max 小于遍历到的数字，则更新 max 的值
        max <- num[i]
    if num[i] < min:         // 如果 min 小于遍历到的数字，则更新 min 的值
        min <- num[i]
Print max , min              // 输出 max 和 min 的值
```
分治算法
```
输入 arr[1...n]           // 输入 n 个数字
arr_max(x , y) :          // 设计一个递归函数，[x , y] 用来限定查找最大数的范围
    if y-x ≤ 1 :         // 如果 y-x 的值小于等于 1，则比较 arr[x] 和 arr[y] 的值，大的就是最大值 
        return max(arr[x] , arr[y])
    else :
        // 将 [x , y] 区域划分为 [x , ⌊(x+y)/2⌋ ] 和 [ ⌊(x+y)/2+1⌋ , y] 两个区域，求出两个区域内各自的最大值
        max1 <- arr_max(x , ⌊(x+y)/2⌋ )    
        max2 <- arr_max( ⌊(x+y)/2+1⌋ , y)
    return max(max1 , max2)   // 比较两个区域的最大值，最终找出 [x , y] 中的最大值
```

#### 汉诺塔问题

汉诺塔问题源自印度一个古老的传说，印度教的“创造之神”梵天创造世界时做了 3 根金刚石柱，其中的一根柱子上按照从小到大的顺序摞着 64 个黄金圆盘。梵天命令一个叫婆罗门的门徒将所有的圆盘移动到另一个柱子上，移动过程中必须遵守以下规则：

- 每次只能移动柱子最顶端的一个圆盘；
- 每个柱子上，小圆盘永远要位于大圆盘之上；

在汉诺塔问题中，3 个圆盘至少需要移动 7 次，移动 n 的圆盘至少需要操作 $2^n-1$ 次。随着圆盘数量的增多，汉诺塔问题会越来越难。也就是说，圆盘的个数直接决定了汉诺塔问题的难度，解决这样的问题可以尝试用分治算法，将移动多个圆盘的问题分解成多个移动少量圆盘的小问题，这些小问题很容易解决，从而可以找到整个问题的解决方案。

将 3 个柱子分别命名为起始柱、目标柱和辅助柱。实际上，解决汉诺塔问题是有规律可循的：

1. 当起始柱上只有 1 个圆盘时，直接将它移动到目标柱上；
2. 当起始柱上有 2 个圆盘时，先将起始柱上的 1 个圆盘移动到辅助柱上，然后将起始柱上遗留的圆盘移动到目标柱上，最后将辅助柱上的圆盘移动到目标柱上。
3. 当起始柱上有 3 个圆盘时，先将起始柱上的 2 个圆盘移动到辅助柱上，然后将起始柱上遗留的圆盘移动到目标柱上，最后将辅助柱上的圆盘移动到目标柱上。

通过分析以上 3 种情况的移动思路，可以总结出一个规律：对于 n 个圆盘的汉诺塔问题，移动圆盘的过程是：

- 将起始柱上的 n-1 个圆盘移动到辅助柱上；
- 将起始柱上遗留的 1 个圆盘移动到目标柱上；
- 将辅助柱上的所有圆盘移动到目标柱上。

由此，n 个圆盘的汉诺塔问题就简化成了 n-1 个圆盘的汉诺塔问题。按照同样的思路，n-1 个圆盘的汉诺塔问题还可以继续简化，直至简化为移动 3 个甚至更少圆盘的汉诺塔问题。

```
// num 表示移动圆盘的数量，source、target、auxiliary 分别表示起始柱、目标柱和辅助柱
hanoi(num , source , target , auxiliary): 
    if num == 1:     // 如果圆盘数量仅有 1 个，则直接从起始柱移动到目标柱
        print(从 source 移动到 target)
    else:
        // 递归调用 hanoi 函数，将 num-1 个圆盘从起始柱移动到辅助柱上，整个过程的实现可以借助目标柱
        hanoi(num-1 , source , auxiliary , target)
        // 将起始柱上剩余的最后一个大圆盘移动到目标柱上
        print(从 source 移动到 target) 
        // 递归调用 hanoi 函数，将辅助柱上的 num-1 圆盘移动到目标柱上，整个过程的实现可以借助起始柱               
        hanoi(n-1 , auxiliary , target , source)
```

### 贪心算法
贪心算法是所有算法中最简单，最易实现的算法，该算法之所以“贪心”，是因为算法中的每一步都追求最优的解决方案。

举个例子，假设有 1、2、5、10 这 4 种面值的纸币，要求在不限制各种纸币使用数量的情况下，用尽可能少的纸币拼凑出的总面值为 18。贪心算法的解决方案如下：

1. 率先选择一张面值为 10 的纸币，可以最大程度上减少需要拼凑的数额（剩余 8）；
1. 选择一张面值为 5 的纸币，需要拼凑的数额降为 3；
1. 选择一张面值为 2 的纸币，需要拼凑的数额降为 1；
1. 选择一张面值为 1 的纸币，完成拼凑。

可以看到，每一步都力求最大限度地解决问题，每一步都选择的是当前最优的解决方案，这种解决问题的算法就是贪心算法。

注意，虽然贪心算法每一步都是最优的解决方案，但整个算法并不一定是最优的。仍以选纸币为例，假设有 1、7、10 这 3 种面值的纸币，每种纸币使用的数量不限，要求用尽可能少的纸币拼凑出的总面值为 15，贪心算法的解决方案为：

1. 选择一张面值为 10 的纸币，需要拼凑的数额降为 5；
1. 选择一张面值为 1 的纸币，需要拼凑的数额降为 4；
1. 选择一张面值为 1 的纸币，需要拼凑的数额降为 3；
1. 选择一张面值为 1 的纸币，需要拼凑的数额降为 2；
1. 选择一张面值为 1 的纸币，需要拼凑的数额降为 1；
1. 选择一张面值为 1 的纸币，完成拼凑。

最终贪心算法给出的解决方案是 10+1+1+1+1+1 共 6 张纸币，但是通过思考，最优的解决方案应该是只需要用 3 张纸币（7+7+1）。

总的来讲，贪心算法注重的是每一步选择最优的解决方案（又称“局部最优解”），并不关心整个解决方案是否最优。

部分背包问题是使用贪心算法解决的典型案例之一，此外它还经常和其它算法混合使用，例如克鲁斯卡尔算法、迪杰斯特拉算法等。

#### 部分背包问题

在限定条件下，如何从众多物品中选出收益最高的几件物品，这样的问题就称为背包问题。

举个简单的例子，商店的货架上摆放着不同重量和价值的商品，一个小偷在商店行窃，他携带的背包只能装固定重量的商品，选择哪些商品才能获得最大的收益呢？这个问题就属于背包问题，限定条件是背包的承重，最终目标是令背包中存放的物品的总收益最高。

根据不同的限定条件，背包问题还可以有更细致的划分：

- 0-1 背包问题：每件物品都不可再分，要么整个装入背包，要么放弃，不允许出现类似“将物品的 1/3 装入背包”的情况；
- 部分背包问题：每件物品是可再分的，即允许将某件物品的一部分（例如 1/3）放入背包；
- 完全背包问题：挑选物品时，每件物品可以选择多个，也就是说不限物品的数量。
- 多重背包问题：每件物品的数量是有严格规定的，比如物品 A 有 2 件，物品 B 有 3 件。

不同的背包问题，对应的解决方案也不相同。

##### 贪心算法解决部分背包问题

假设商店中有 3 种商品，它们各自的重量和收益是：

- 商品 1：重量 10 斤，收益 60 元；
- 商品 2：重量 20 斤，收益 100 元；
- 商品 3：重量 30 斤，收益 120 元。

对于每件商品，顾客可以购买商品的一部分（可再分）。一个小偷想到商店行窃，他的背包最多只能装 50 斤的商品，如何选择才能获得最大的收益呢？

贪心算法解决此问题的思路是：计算每个商品的收益率（收益/重量），优先选择收益率最大的商品，直至所选商品的总重量达到 50 斤。

```
// w 存储各个商品的重量，p 存储各个商品的收益，W 表示背包的承重
fractional_knapsack(w[] , p[] , W):
    sort(w , p)                   //根据收益率对商品进行排序
    i <- 0
    while W > 0:                  //只要背包还有剩余空间，就一直装
        temp <- min(W , w[i])      //判断该商品能否全部装入
        result[i] <- temp/w[i]    //将实际装入到背包中的商品量以百分比的方式存储起来
        W <- W - temp             //计算背包的剩余容量，为装后续商品做准备
        i <- i + 1
    return result                 //返回统计装入信息的 result
```

### 动态规划算法
动态规划算法解决问题的过程和分治算法类似，也是先将问题拆分成多个简单的小问题，通过逐一解决这些小问题找到整个问题的答案。不同之处在于，分治算法拆分出的小问题之间是相互独立的，而动态规划算法拆分出的小问题之间相互关联，例如要想解决问题 A，必须先解决问题 B 和 C。

假设有 1、7、10 这 3 种面值的纸币，每种纸币使用的数量不限，要求用尽可能少的纸币拼凑出的总面值为 15。

动态规划算法的解题思路是：用 f(n) 表示凑齐面值 n 所需纸币的最少数量，面值 15 的拼凑方案有 3 种，分别是：

- f(15) = f(14) +1：挑选一张面值为 1 的纸币，f(14) 表示拼凑出面值 14 所需要的最少的纸币数量；
- f(15) = f(8) + 1：挑选一张面值为 7 的纸币，f(8) 表示拼凑出面值 8 所需要的最少的纸币数量；
- f(15) = f(5) + 1：选择一张面值为10 的纸币，f(5) 表示拼凑出面值 5 所需要的最少的纸币数量。

也就是说，f(14)+1、f(8)+1 和 f(5)+1 三者中的最小值就是最优的拼凑方案。采用同样的方法，继续求 f(14)、f(8)、f(5) 的值：

- f(5) = f(4) + 1；
- f(8) = f(7) + 1 = f(1) +1；
- f(14) = f(13)+1 = f(7) + 1 = f(4) +1。

经过不断地拆分，f(15) 最终会和 f(0)、f(1)、f(2) 等产生关联，而 f(0)、f(1)、f(2) 的值是很容易计算的。在得知 f(0)、f(1)、f(2) 等简单问题的结果后，就可以轻松推算出 f(3)~f(14) 的值，最终可以推算出 f(15) 的值。

对于每种纸币来说，是否使用它可能会影响 f(n) 的值。

1) 在不能使用任何纸币的情况下，f(1)~f(15) 没有对应的值。
2) 使用面值为 1 的纸币，f(1)~f(14) 对应的值都可以优化，计算方式是：f(1)=f(0)+1，f(2)=f(1)+1，f(3)=f(2)+1... f(15)=f(14)+1 。
3) 使用面值为 7 的纸币，可以对 2 中各个拼凑方案做进一步优化：f(7)=f(0)+1，f(8)=f(1)+1，...，f(15)=f(8)+1。
4) 使用面值为 10 的纸币，继续进行优化：面值为 10 的纸币仅对 f(10)~f(13) 起到了优化的作用，而对于 f(14) 和 f(15) 来说，选择面值为 10 的纸币，并没有先前的解决方案好。最终，f(15) 的最优拼凑方案是只需要 3 张纸币（7+7+1）。

总的来说，动态规划算法就是不断地拆分问题，拆分出的这些小问题之间相关关联，通过解决一些简单的问题，复杂的问题也能迎刃而解。

0-1 背包问题则可以用动态规划算法解决。此外，弗洛伊德算法在解决最短路径问题的过程中，也用到了“动态规划”的思想。

#### 01背包问题

0-1 背包问题：所有物品不可再分，要么整个装入背包，要么放弃，不允许出现“仅选择物品的 1/3 装入背包”的情况；

虚拟一个场景，商店中拥有 5 件商品，它们各自的重量和收益分别是：

- 商品 1：重量 1 斤，收益 1 元；
- 商品 2：重量 2 斤，收益 6 元；
- 商品 3：重量 5 斤，收益 18 元；
- 商品 4：重量 6 斤，收益 22 元；
- 商品 5：重量 7 斤，收益 28 元。

所有商品不可再分，顾客要么“整件”购买商品，要么放弃购买。一个小偷想窃取商品，他的背包只能装 11 斤商品，如何选择商品才能获得最大的收益呢？

动态规划算法解决此问题的核心思想是：背包承重 1 斤时所能获得的最大收益是很容易计算的，在此基础上，可以推算出背包承重 2 斤、3斤、...、14斤、15斤时所能获得的最大收益。建立如下这张表格，依次将各个商品装入不同承重的背包中，计算出它们所能获得的最大收益。

1) 首先考虑将商品一装入各个背包，除了承重值为 0 的背包，其它背包都能装入，且与不装任何商品相比，装入商品一后各个背包的收益更大，各个背包的收益值：
2) 考虑将商品二装入各个背包，除了承重值为 0 和 1 的背包，其它背包都可以装入。
3) 考虑将商品三装入各个背包，除了承重值为小于 5 的背包，其它背包都可以装入。
4) 采用同样的方法将其它商品装入各个背包。

| 商品种类	/背包承重 | 0    | 1    | 2    | 3    | 4    | 5    | 6    | 7    | 8    | 9    | 10   | 11   |
| --------------------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| 不装任何商品          | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    | 0    |
| w1 = 1，v1 = 1        | 0    | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 1    | 1    |
| w2 = 2，v2 = 6        | 0    | 1    | 6    | 7    | 7    | 7    | 7    | 7    | 7    | 7    | 7    | 7    |
| w3 = 5，v3 = 18       | 0    | 1    | 6    | 7    | 7    | 18   | 19   | 24   | 25   | 25   | 25   | 25   |
| w4 = 6，v4 = 22       | 0    | 1    | 6    | 7    | 7    | 18   | 22   | 24   | 28   | 29   | 29   | 40   |
| w5 = 7，v5 = 28       | 0    | 1    | 6    | 7    | 7    | 18   | 22   | 28   | 29   | 34   | 35   | 40   |

```
输入 N    // 指定商品种类
输入 W    // 指定背包载重量
//w[] 记录各个商品的载重量，v[] 记录各个商品对应的收益
knapsack01(w[] , v[]):
    //逐个遍历每个商品
    for i <- 1 to N：
        //求出从 1 到 W 各个载重量对应的最大收益
        for j <- 1 to W:
            //如果背包载重量小于商品总重量，则商品无法放入背包，收益不变
            if  j < w[i]:
                result[i][j] <- result[i-1][j]
            else:
                //比较装入该商品和不装该商品，哪种情况获得的收益更大，记录最大收益值
                result[i][j] <- max(result[i-1][j] , v[i]+result[i-1][j]])
    return result 
```

### 回溯算法

回溯算法和穷举法很像，它也会把所有可能的方案都查看一遍，从中找到正确答案。不同之处在于，回溯算法查看每种方案时，一旦判定其不是正确答案，会立即以“回溯”的方式试探其它方案。

所谓“回溯”，其实就是回退、倒退的意思。回溯算法采用“回溯”（回退）的方式对所有的可行方案做出判断，并最终找到正确方案。和穷举法相比，回溯算法的查找效率往往更高，因为在已经断定当前方案不可行的情况下，回溯算法能够“悬崖勒马”，及时转向去判断其它的可行方案。

回溯算法经常以递归的方式实现，用来解决以下 3 类问题：

- 决策问题：从众多选择中找到一个可行的解决方案；
- 优化问题：从众多选择中找到一个最佳的解决方案；
- 枚举问题：找出能解决问题的所有方案。

用回溯算法解决的经典问题有 N皇后问题、迷宫问题等。

#### 迷宫问题

迷宫问题指的是：在给定区域内，找到一条甚至所有从某个位置到另一个位置的移动路线。

回溯算法解决此问题的具体思路是：

1. 从当前位置开始，分别判断是否可以向 4 个方向（上、下、左、右）移动：
2. 选择一个方向并移动到下个位置。判断此位置是否为终点，如果是就表示找到了一条移动路线；如果不是，在当前位置继续判断是否可以向 4 个方向移动；
3. 如果 4 个方向都无法移动，则回退至之前的位置，继续判断其它的方向；
4. 重复 2、3 步，最终要么成功找到可行的路线，要么回退至起点位置，表明所有的路线都已经判断完毕。

程序中，可以用特殊的字符表示迷宫中的不同区域。例如，用 1 表示可以移动的白色区域，用 0 表示不能移动的黑色区域。

```
输入 maze[ROW][COL]   //输入迷宫地图，0 表示黑色区域，1 表示可行走区域
//(row,col) 表示起点，(outrow,outcol)表示终点
maze_puzzle(maze,row,col,outrow,outcol):
    //回溯过程中，行走的每一区域都设为 Y，表示已经进行了判断
    maze[row][col] <- 'Y'
    //如果行走至终点，表明有从起点到终点的路线
    if row == outrow && col == outcol:
        Print maze  // 输出行走路线
        return
    //判断是否可以向上移动
    if canMove(maze,row-1,col):
        maze_puzzle(maze,row-1,col,outrow,outcol)
    //判断是否可以向左移动
    if canMove(maze,row,col-1):
        maze_puzzle(maze,row,col-1,outrow,outcol)
    //判断是否可以向下移动
    if canmove(maze,row+1,col):
        maze_puzzle(maze,row+1,col,outrow,outcol)
    //判断是否可以向右移动
    if canmove(maze,row,col+1):
        maze_puzzle(maze,row,col+1,outrow,outcol)

```

#### N皇后问题

N 皇后问题源自国际象棋，所有棋子中权力最大的称为皇后，它可以直着走、横着走、斜着走（沿 45 度角），可以攻击移动途中遇到的任何棋子。N 皇后问题的具体内容是：如何将 N 个皇后摆放在 N\*N 的棋盘中，使它们无法相互攻击。

要想使 N 个皇后不相互攻击，应将它们放置在不同的行、不同的列、还不能位于同一条 45°（或 135°）角的斜线上。

回溯算法解决N皇后问题的具体思路是：将 N 个皇后逐一放置在不同的行，以“回溯”的方式逐一测试出每行皇后所在行的具体位置，最终确定所有皇后的位置。
```
输入 N      // 输入皇后的个数
q[1...N]    //存储每行的皇后的具体位置（列标）
n_queens(k , n):    // 确定第 k 行皇后的位置
    if k > n:             // 递归的出口
        Print q          // 输出各个皇后的位置
    else:
        for j <- 1 to n:      // 从第 k 行第 1 列开始，判断各个位置是否可行
            if isSafe(k , j):    // 如果可行，继续判断下一行
                q[k] <- j        // 将第 k 行皇后放置的位置 j 记录下来
                n_queens(k+1 , n)    // 继续判断下一行皇后的位置
```

### 排序算法

#### 冒泡排序算法

冒泡排序是所有排序算法中最简单、最易实现的算法，有时也称为起泡排序算法。

使用冒泡排序算法对 n 个数据进行排序，实现思路是：从待排序序列中找出一个最大值或最小值，这样的操作执行 n-1 次，最终就可以得到一个有序序列。
```
Bubble_sort(list):                         // list 表示待排序序列
    for i <- 0 to length(list) - 1:        // 对于元素个数为 n 的 list 序列，需遍历 n-1 次，这里用 [0,length(list)-1) 表示。
        for j <- 1 to length(list) - i:    // 从第 1 个元素开始遍历，遍历区间为 [1,length(list)-i)。
            if list[j] > list[j+1]:        // 若进行降序排序，则改成 < 小于号
                 swap(list[j] , list[j+1]) // 交换 2 个相邻元素的位置
    return list                            // 返回排好序的序列
```

根据伪代码，冒泡排序算法的时间复杂度为$O(n^2)$。

#### 插入排序算法

插入排序算法可以对指定序列完成升序（从小到大）或者降序（从大到小）排序，对应的时间复杂度为$O(n^2)$。

插入排序算法的实现思路是：初始状态下，将待排序序列中的第一个元素看作是有序的子序列。从第二个元素开始，在不破坏子序列有序的前提下，将后续的每个元素插入到子序列中的适当位置。

```
// list 为待排序序列
insertion_sort(list):
    // 从第 2 个元素开始遍历序列
    for i <- 2 to length(list):
        // 记录要插入的目标元素
        insert_elem <- list[i]
        // 记录目标元素所在的位置
        position <- i
        // 从 position 所在位置向前遍历，直至找到一个比目标元素小的元素，目标元素插入到该元素之后的位置
        while position > 0 and list[position-1] > insert_elem:  // 此为升序排序，实现降序排序改为 list[position-1] < insert_elem
            // 移动前一个元素的位置，将其向后移动一个位置
            list[position] <- list[position-1]
            position <- position - 1
        if(position != i):
            list[position] <- insert_elem
    return list
```

#### 选择排序算法

对数据量较少的序列实现升序或降序排序，可以考虑使用选择排序算法，它对应的时间复杂度为$O(n^2)$。

排序排序算法对含有 n 个元素的序列实现排序的思路是：每次从待排序序列中找出最大值或最小值，查找过程重复 n-1 次。对于每次找到的最大值或最小值，通过交换元素位置的方式将它们放置到适当的位置，最终使整个序列变成有序序列。

选择排序算法可以看作是冒泡排序算法的“改良版”。和后者相比，选择排序算法大大减少了交换数据存储位置的操作。

```
selection_sort(list):   // list 为待排序序列
    n <- length(list)   // 记录序列中的元素个数
    for i <- 1 to n-1:  // 从第 1 个元素一直遍历至倒数第 2 个元素
        min <- i        // 初始化最小值为第 i 个元素
        for j <- i+1 to n: // 从第 i+1 个元素开始开始遍历序列
            if list[j] < list[min]:  // 查找待排序序列中的最小值
                min = j
        if min != i:     // 如果最小值所在的位置不为 i，交换最小值和第 i 个元素的位置
            swap list[min] , list[i]
    return list
```

#### 希尔排序算法

希尔排序算法又叫缩小增量排序算法，是一种更高效的插入排序算法。和普通的插入排序算法相比，希尔排序算法减少了移动元素和比较元素大小的次数，从而提高了排序效率。

希尔排序算法的实现思路是：

- 将待排序序列划分成多个子序列，使用普通的插入排序算法对每个子序列进行排序；
- 按照不同的划分标准，重复执行第一步；
- 使用普通的插入排序算法对整个序列进行排序。

待排序序列如何进行划分，划分多少次，都会影响到希尔排序算法的执行效率。

希尔排序算法没有固定的划分标准，常用的方法如下伪代码：

```
输入 list           // 输入待排序序列
interval <- 1    // 初始值为 1
while interval < length(list) / 3:    // length(list) 表示待排序序列的长度
    interval = interval * 3 + 1
```
经过计算得出的 interval 的值，就是首次划分序列采用的标准。后续划分整个序列，套用如下公式：
`interval = (interval-1)/3`

```
// list 为待排序序列
shell_sort(list):
    len <- length(list)  // 记录 list 序列中的元素个数
    // 初始化间隔数为 1
    interval <- 1
    // 计算最大间隔数
    while interval < len/3:
        interval <- interval * 3 + 1
    // 根据间隔数，不断划分序列，并对各子序列排序
    while interval > 0:
        // 对各个子序列做直接插入排序
        for i <- interval to len:
            temp <- list[i]
            j <- i
            while j > interval - 1 && list[j - interval] ≥ temp:
                list[j] <- list[j - interval]
                j <- j - interval
            if j != i:
                list[j] <- temp
        // 计算新的间隔数，继续划分序列
        interval <- (interval - 1)/3
return  list
```

希尔排序耗时的操作有：比较 + 后移赋值。希尔排序的执行时间依赖于增量序列。 

1) 最好情况：序列是正序排列，在这种情况下，需要进行的比较操作需（n-1）次。后移赋值操作为0次。即O(n)
2) 最坏情况：$O(n\log{2n})$。
3) 渐进时间复杂度（平均时间复杂度）：$O(n\log{2n})$

希尔排序是按照不同步长对元素进行插入排序，当刚开始元素很无序的时候，步长最大，所以插入排序的元素个数很少，速度很快；当元素基本有序了，步长很小，插入排序对于有序的序列效率很高。所以，希尔排序的时间复杂度会比$O(n^2)$好一些。

希尔算法在最坏的情况下和平均情况下执行效率相差不是很多，与此同时快速排序在最坏的情况下执行的效率会非常差。希尔排序没有快速排序算法快，因此中等大小规模表现良好，对规模非常大的数据排序不是最优选择。

#### 归并排序算法

归并排序算法是在分治算法基础上设计出来的一种排序算法，它可以对指定序列完成升序（由小到大）或降序（由大到小）排序，对应的时间复杂度为$O(n\log{n})$。

归并排序算法实现排序的思路是：

1. 将整个待排序序列划分成多个不可再分的子序列，每个子序列中仅有 1 个元素；
2. 所有的子序列进行两两合并，合并过程中完成排序操作，最终合并得到的新序列就是有序序列。

```
输入 arr[n]                                // 输入要排序的序列
merge_sort(arr[n] , p , q):                // [p , q] 表示对第 p ~ q 区域内的元素进行归并排序
    if p < q :                             // 对 [p , q] 区域不断采用对半分割的方式，最终将整个区域划分为多个仅包含 1 个元素（p==q）的序列
        mid = ⌊(p+q)/2⌋
        merge_sort(arr , p , mid)
        merge_sort(arr , mid+1 , q)
        merge(arr , p , mid , q)          // 调用实现归并过程的代码模块
```

```
merge(arr[n] , p , mid , q):                          // 该算法表示将 [p , mid] 和 [mid+1 , q] 做归并操作
    leftnum <- mid - p + 1                            // 统计 [p , mid] 区域内的元素个数
    rightnum <- q - mid                               // 统计 [mid+1 , q] 区域内的元素个数
    leftarr[leftnum] <- arr[p ... mid]                // 分别将两个区域内的元素各自拷贝到另外两个数组中
    rightarr[rightnum] <- arr[mid+1 ... q]
    i <- 1 , j <- 1
    for k <- p to q :             // 从 leftarr 和 rightarr 数组中第 1 个元素开始，比较它们的大小，将较小的元素拷贝到 arr 数组的 [p , q] 区域
        if leftarr[i] ≤ rightarr[j] :
            arr[k] = leftarr[i]
            i <- i+1
        else :
            arr[k] = right[j]
            j <- j+1
```

#### 快速排序算法

快速排序算法是在分治算法基础上设计出来的一种排序算法，和其它排序算法相比，快速排序算法具有效率高、耗费资源少、容易实现等优点。

快速排序算法的实现思路是：

1. 从待排序序列中任选一个元素（假设为 pivot）作为中间元素，将所有比 pivot 小的元素移动到它的左边，所有比 pivot 大的元素移动到它的右边；
2. pivot 左右两边的子序列看作是两个待排序序列，各自重复执行第一步。直至所有的子序列都不可再分（仅包含 1 个元素或者不包含任何元素），整个序列就变成了一个有序序列。

真正实现快速排序算法时，通常会挑选待排序序列中第一个元素或者最后一个元素作为中间元素。

```
输入 arr[]                              // 输入待排序序列
quick_sort(arr[] , p , q):              // [p , q] 用于指定当前要处理的子序列
    if q-p <= 0:                        // 如果序列中没有元素或者仅包含 1 个元素，则直接返回
        return
    else:
        par <- partition(arr , p , q)   // partition()函数用于将 [p,q] 区域分割成 [p, par-1] 和 [par+1, q] 区域，[p, par-1] 区域的元素都比 pivot 小，[par+1 , q] 区域的元素都比 pivot 大，函数会返回中间元素 pivot 所在的位置。
        quick_sort(arr , p , par-1)     // 将 [p , par-1] 作为待排序序列，重复进行分割
        quick_sort(arr , par+1 , q)     // 将 [par+1 , q] 作为待排序序列，重复进行分割
```

```
partition(arr[] , p , q):              // [p , q] 为要分割的区域
    lo <- p                            // lo、hi 准备遍历 [p , q-1] 区域
    hi <- q-1
    pivot <- arr[q]                    // 以 [p , q] 区域中最后一个元素作为中间值
    while true：                       // 一直循环，直到执行 end while
        while arr[lo] < pivot:         // lo 从左往右遍历，直至找到一个不小于 pivot 的元素
            lo <- lo+1
        while hi>0 and arr[hi] > pivot:   // hi 从右往左遍历，直至找到一个不小于 pivot 的元素
            hi <- hi-1
        if lo ≥ hi:                      // 如果 lo 大于等于 hi，退出循环
            end while
        else:
            swap arr[lo] , arr[hi]        // 交换 arr[lo] 和 arr[hi] 的值
            lo <- lo+1                    // 分别将 lo 和 hi 向前移动一步，准备遍历后续的元素
            hi <- hi-1
    swap arr[lo] , arr[q]                 // 跳出循环后，交换 arr[lo] 和 arr[q] 的值
    return lo                             // 返回 lo 的值，也就是中间值所在序列中的位置
```
最坏情况下，快速排序算法的时间复杂度为$O(n^2)$，理想状态对应的时间复杂度为$O(n\log{n})$。

#### 计数排序算法

通过统计序列中各个元素出现的次数，完成对整个序列的升序或降序排序，这样的排序算法称为计数排序算法。

假设待排序序列为 {4, 2, 2, 8, 3, 3, 1}，使用计数排序算法完成升序排序的过程为：
1) 找到序列中的最大值（用 max 表示）。对于 {4, 2, 2, 8, 3, 3, 1} 序列来说，最大值是 8。
2) 创建一个长度为 max+1、元素初值全部为 0 的数组，为数组中 [1,max] 区域内的各个空间建立索引：
- 找到序列中的最小值（用 min 表示），作为数组下标为 1 的存储空间的索引；
- 将 max 作为数组下标为 max 的存储空间的索引；
- 将 max-1 作为数组下标为 max-1 的存储空间的索引；
- 将 max-2 作为数组下标为 max-2 的存储空间的索引；
- ......
3) 统计待排序序列中各个元素的出现次数，存储到以该元素为索引的数组空间中。例如，待排序序列中元素 2 出现了两次，所以索引（下标）为 2 的数组空间中存储 2 。
4) 进一步加工数组中存储的数据。从数组下标为 1 的位置开始，按照如下公式修改数组中存储的元素：
`array[i] = array[i-1] + array[i]`，其中 i 的取值范围是 [1, max]。
5) 遍历待排序列中的元素，以该元素为索引获取数组中存储的值，此值即为序列排序后元素应处的位置。
6) 当确定了一个元素排序后的位置，需要将数组中该元素为索引对应的值减去 1。

```
// 计数排序算法，list 为待排序序列
countingSort(list)
    size <- len(list)      // 获取 list 序列中的元素个数=
    max <- getMax(list)    // 找到 list 序列中的最大值
    array[0...max+1] <- 0    // 定义一个长度为 max+1 的数组，
    for j <- 0 to size      // 创建 array[max+1] 并统计各个元素的出现次数
        array[list[j]] <- array[list[j]] + 1
    for i <- 1 to max       // 对 array[max+1] 存储的元素做累加操作
        array[i] <- array[i] + array[i - 1];
    for j <- size to 0 // 根据 array[max+1] 中的累加值，找到各个元素排序后的具体位置
        output[array[list[i]] - 1] = list[i]; // output存储有序序列
        array[list[i]] <- array[list[i]] - 1  // 确定一个元素的位置后，array[max+1] 中相应位置的数值要减 1
    return output[size]
```

时间复杂度为O(n)


#### 基数排序算法

基数排序算法适用于对多个整数或者多个字符串进行升序或降序排序。

基数排序算法的实现思路是：对于待排序序列中的各个元素，依次比较它们包含的各个数字或字符，根据比较结果调整各个元素的位置，最终就可以得到一个有序序列。

对于待排序的整数序列，依次比较各个整数的个位数、十位数、百位数......，数位不够的用 0 表示；对于待排序的字符串序列，依次比较各个字符串的第一个字符、第二个字符、第三个字符......，位数不够的用 NULL 表示。

```
// 基数排序算法，array 为待排序序列
radixSort(array):
    max = getMax(array)   // 查找 array 序列中的最大值
    place <- 1            // 默认从个位开始排序
    while max/place > 0 : // 将最大值的位数作为循环次数
        countingSort(array, place)  // 调用计数排序算法，根据所选数位对各个元素进行排序
        place = place * 10

// 计数排序算法，array 为待排序序列，place 指排序所依照的数位
countingSort(array, place)
    size <- len(array)       // 获取 array 序列中的元素个数
    // 根据 place，找到相应数位值最大的元素
    max <- (array[0] / place) % 10    
    for i <- 1 to size:
        if (array[i] / place) % 10 > max：
            max <- array[i]
    // 创建 count[max+1]，统计各个元素的出现次数
    for j <- 0 to size     
        count[(array[i] / place) % 10] <- count[(array[i] / place) % 10] + 1
    // 对 count[max+1] 存储的元素做累加操作
    for i <- 1 to max
        count[i] <- count[i] + count[i - 1];
    // 根据 count[max+1] 中的累加值，找到各个元素排序后的具体位置
    for j <- size down to 0
        output[count[(array[i] / place) % 10] - 1] <- array[i];
        // 确定一个元素的位置后，count[max+1] 中相应位置的数值要减 1
        count[(array[i] / place) % 10] <- count[(array[i] / place) % 10] - 1 
    return output[size]
```

#### 桶排序算法

桶排序（又称箱排序）是一种基于分治思想、效率很高的排序算法，理想情况下对应的时间复杂度为 O(n)。

假设一种场景，对 {5, 2, 1, 4, 3} 进行升序排序，桶排序算法的实现思路是：

- 准备 5 个桶，从 1~5 对它们进行编号；
- 将待排序序列的各个元素放置到相同编号的桶中；
- 从 1 号桶开始，依次获取桶中放置的元素，得到的就是一个升序序列。

```
// 桶排序算法，array 为待排序序列
bucketSort(array):
    bucket = []
    // 创建空桶
    for i <- 1 to len(array):
        bucket.append([])
    // 根据规则将所有元素分散到各个桶中
    for j <- 1 to len(array):
        index_b = int(10 * j)
        bucket[index_b].append(j)
    // 分别对各个桶进行排序
    for i <- 1 to len(array):
        bucket[i] = sorted(bucket[i])
    // 合并所有桶内的元素
    k = 0
    for i <- 1 to len(array):
        for j <- 1 to len(bucket[i]):
            array[k] = bucket[i][j]
            k += 1
    return array

```

#### 稳定排序算法

评价一个排序算法是否稳定，是指该算法完成排序的同时，是否会改变序列中相同元素的相对位置。

除了稳定性，某些场景中还需要使用就地排序算法。

“就地排序”的含义是：排序算法在排序过程中，主要使用待排序序列占用的内存空间，最多额外创建几个辅助变量，不再申请过多的辅助空间。也就是说，就地排序算法指的是直接将待排序序列修改成有序序列的排序算法，而不是新创建一个有序序列。

就地排序算法的空间复杂度为 O(1)。

| 排序算法     | 稳定排序 | 就地排序 |
| ------------ | -------- | -------- |
| 冒泡排序算法 | 稳定     | 是       |
| 插入排序算法 | 稳定     | 是       |
| 希尔排序算法 | 不稳定   | 是       |
| 选择排序算法 | 不稳定   | 是       |
| 归并排序算法 | 稳定     | 不是     |
| 快速排序算法 | 不稳定   | 是       |
| 计数排序算法 | 不稳定   | 不是     |
| 基数排序算法 | 不稳定   | 不是     |
| 桶排序算法   | 不稳定   | 不是     |

### 查找算法
#### 顺序查找算法

顺序查找算法又称顺序搜索算法或者线性搜索算法，是所有查找算法中最基本、最简单的，对应的时间复杂度为O(n)。

```
arr[1...N]                        // 待查找序列
linear_search(arr , value):       // value 表示要查找的目标元素
    for i <-1 to length(arr):     // 从 arr 序列中第一个元素开始遍历，直至最后一个元素
        if arr[i] == value:       // 如果成功找到一个元素和目标元素匹配，则返回该元素所处的位置
            return i                    
    return -1                     // 返回 -1，表示查找失败。
```

某些场景中，待查找序列可能包含多个目标元素，需要全部找到。这种情况下，顺序查找算法仍然适用，只需对实现过程做一下微调即可：
```
arr[1...N]       //待查找序列
index[1...N]     //存储目标元素的位置
j <- 1
linear_search(arr , value):       // value 表示要查找的目标元素
    for i <-1 to length(arr):     // 从 arr 序列中第一个元素开始遍历，直至最后一个元素
        if arr[i] == value:       // 如果成功找到一个元素和目标元素匹配，则返回该元素所处的位置
            index[j] <- i         // 将目标元素所在序列的位置存储到 index 中
            j <- j + 1            // j 自加，为下次在 index 中存储目标元素的位置做准备       
    return index
```
#### 二分查找算法

二分查找又称折半查找、二分搜索、折半搜索等，是在分治算法基础上设计出来的查找算法，对应的时间复杂度为$O(\log{n})$。

二分查找算法仅适用于有序序列，它只能用在升序序列或者降序序列中查找目标元素。

在有序序列中，使用二分查找算法搜索目标元素的核心思想是：不断地缩小搜索区域，降低查找目标元素的难度。

以在升序序列中查找目标元素为例，二分查找算法的实现思路是：

- 初始状态下，将整个序列作为搜索区域（假设为 [B, E]）；
- 找到搜索区域内的中间元素（假设所在位置为 M），和目标元素进行比对。如果相等，则搜索成功；如果中间元素大于目标元素，表明目标元素位于中间元素的左侧，将 [B, M-1] 作为新的搜素区域；反之，若中间元素小于目标元素，表明目标元素位于中间元素的右侧，将 [M+1, E] 作为新的搜素区域；
- 重复执行第二步，直至找到目标元素。如果搜索区域无法再缩小，且区域内不包含任何元素，表明整个序列中没有目标元素，查找失败。

```
输入 arr[]                                // 输入有序序列
binary_search( arr , begin , end , ele):  // [begin,end] 指定搜索区域，ele 为要搜索的目标元素
    if begin > end:                       // [begin,end] 不存在时，返回一个错误值（比如 -1）
        return -1
    mid <- ⌊ begin+(end-begin)/2 ⌋        // 找到 [begin,end] 区域内中间元素所在位置的下标
    if ele == arr[mid]:                  // 递归的出口，即 ele 和中间元素的值相等
        return mid
    if ele ＜ arr[mid]:                  // 比较 ele 和中间元素的值，进一步缩小搜索区域
        return binary_search(arr , begin , mid-1 , ele)
    else:
        return binary_search(arr , mid+1 , end , ele)
```

#### 插值查找算法

插值查找算法又称插值搜索算法，是在二分查找算法的基础上改进得到的一种查找算法。

插值查找算法只适用于有序序列，换句话说，它只能在升序序列或者降序序列中查找目标元素。作为“改进版”的二分查找算法，当有序序列中的元素呈现均匀分布时，插值查找算法的查找效率要优于二分查找算法；反之，如果有序序列不满足均匀分布的特征，插值查找算法的查找效率不如二分查找算法。

插值查找算法的解题思路和二分查找算法几乎相同，唯一的区别在于，每次与目标元素做比较的元素并非搜索区域内的中间元素，此元素的位置需要通过如下公式计算得出：
```
Mid = Begin + ( (End - Begin) / (A[End] - A[Begin]) ) * (X - A[Begin])

Mid：计算得出的元素的位置；
End：搜索区域内最后一个元素所在的位置；
Begin：搜索区域内第一个元素所在的位置；
X：要查找的目标元素；
A[]：表示整个待搜索序列。
```

```
输入 arr[]               // 输入有序序列
输入 ele                 // 输入查找的目标元素  
interpolation_search( arr , begin , end , ele):      // [begin,end] 指定搜索区域，ele 为要搜索的目标元素
    // [begin,end] 不存在时，返回一个错误值（比如 -1）
    if begin > end: 
        return -1
    // [begin,end] 只包含 1 个元素时，判断此元素是否为目标元素
    if begin == end:
        if ele == arr[begin]:
            return begin
        else:
            return -1
    // 找到 [begin,end] 区域“中间值”的下标
    mid <- begin + ( (end-begin)/(arr[end] - arr[begin]) * (ele - arr[begin]) )
    // 递归的出口，即 ele 和中间元素的值相等
    if ele == arr[mid]:                                   
        return mid
    if ele ＜ arr[mid]:         // 比较 ele 和中间元素的值，进一步缩小搜索区域
        return binary_search(arr , begin , mid-1 , ele)
    else:
        return binary_search(arr , mid+1 , end , ele)
```
#### 哈希查找算法

哈希查找算法又称散列查找算法，是一种借助哈希表（散列表）查找目标元素的方法，查找效率最高时对应的时间复杂度为 O(1)。

哈希表（Hash table）又称散列表，是一种存储结构，通常用来存储多个元素。

和其它存储结构（线性表、树等）相比，哈希表查找目标元素的效率非常高。每个存储到哈希表中的元素，都配有一个唯一的标识（又称“索引”或者“键”），用户想查找哪个元素，凭借该元素对应的标识就可以直接找到它，无需遍历整个哈希表。

多数场景中，哈希表是在数组的基础上构建的。哈希表的解决方案是：各个元素并不从数组的起始位置依次存储，它们的存储位置由专门设计的函数计算得出，我们通常将这样的函数称为哈希函数。借助哈希函数，我们提高了数组中数据的查找效率，这就是哈希表存储结构。

构建哈希表时，哈希函数的设计至关重要。如果存在不同的元素对应的索引值是相同的，它们的存储位置就发生了冲突，我们习惯称为哈希冲突或者哈希碰撞。设计一个好的哈希函数，可以降低哈希冲突的出现次数。哈希表提供了很多解决哈希冲突的方案，比如线性探测法、再哈希法、链地址法等。

哈希查找算法就是利用哈希表查找目标元素的算法。对于给定的序列，该算法会先将整个序列存储到哈希表中，然后再查找目标元素。

```
N <- 10          // 指定哈希表的长度
输入 arr[]        // 存储 {5, 20, 30, 50, 55} 待查找序列
// 哈希函数
hash(value):
    return value%10
// 创建哈希表，arr为原序列，hashArr为空的哈希表
createHash(arr, hashArr):
    for i <- 0 to 5:
        index <- hash(arr[i])
        while (hashArr[index % N] !=0):
            index <- index + 1
        hashArr[index] <- arr[i]
// 实现哈希查找算法，value 为要查找的目标元素
hash_serch(hashArr[] , value):           
    hashAdd = hash(value)            // 根据哈希函数，找到对应的索引值
    while hashArr[hashAdd] != value: // 如果哈希表中对应位置不是要查找的目标元（即发生了碰撞）
        hashAdd = (hashAdd + 1) % N  // 获取下一个索引值
        if hashArr[hashAdd] == 0 || hashAdd = hash(value):   // 如果索引值对应的存储位置为空（这里用 -1 表示），或者已经查找了一圈，仍为找到目标元素
            return -1                 // 查找失败（返回 -1 表示查找失败）
    return hashAdd                    // 返回目标元素所在的索引
```

### 最小生成树

数据结构提供了 3 种存储结构，分别称为线性表、树和图。

线性表是最简单的存储结构，很容易分辨。树和图有很多相似之处，它们的区别是：树存储结构中不允许存在环路，而图存储结构中可以存在环路。

根据所有顶点之间是否存在通路，图存储结构可以细分为连通图和非连通图。

生成树，指的是具备以下条件的连通图：

- 包含图中所有的顶点；
- 任意顶点之间有且仅有一条通路。

借助生成树，可以解决实际生活中的很多问题。例如，为了方便 6 座城市中居民的生产和生活，政府要在 6 座城市之间修建公路。本着节约资金的原则，6 座城市只需要建立 5 条公路即可实现连通，如何修建公路才能最大程度上节省资金呢？

在连通图的基础上，我们赋予每条边一个数值，这样的连通图又称连通网。一个连通网对应生成树可能有多种，每个生成树中所有边的权值的总和，就是这个生成树的总权值。

最小生成树指的就是在连通网中找到的总权值最小的生成树。在连通图查找最小生成树，常用的算法有两种，分别称为普里姆算法和克鲁斯卡尔算法。

#### 普里姆算法

普里姆算法查找最小生成树的过程，采用了贪心算法的思想。对于包含 N 个顶点的连通网，普里姆算法每次从连通网中找出一个权值最小的边，这样的操作重复 N-1 次，由 N-1 条权值最小的边组成的生成树就是最小生成树。

那么，如何找出 N-1 条权值最小的边呢？普里姆算法的实现思路是：

1. 将连通网中的所有顶点分为两类（假设为 A 类和 B 类）。初始状态下，所有顶点位于 B 类；
2. 选择任意一个顶点，将其从 B 类移动到 A 类；
3. 从 B 类的所有顶点出发，找出一条连接着 A 类中的某个顶点且权值最小的边，将此边连接着的 A 类中的顶点移动到 B 类；
4. 重复执行第 3  步，直至 B 类中的所有顶点全部移动到 A 类，恰好可以找到 N-1 条边。

#### 克鲁斯卡尔算法

克鲁斯卡尔算法查找最小生成树的方法是：将连通网中所有的边按照权值大小做升序排序，从权值最小的边开始选择，只要此边不和已选择的边一起构成环路，就可以选择它组成最小生成树。对于 N 个顶点的连通网，挑选出 N-1 条符合条件的边，这些边组成的生成树就是最小生成树。

实现克鲁斯卡尔算法的难点在于“如何判断一个新边是否会和已选择的边构成环路”。判断方法：初始状态下，为连通网中的各个顶点配置不同的标记。对于一个新边，如果它两端顶点的标记不同，就不会构成环路，可以组成最小生成树。一旦新边被选择，需要将它的两个顶点以及和它直接相连的所有已选边两端的顶点改为相同的标记；反之，如果新边两端顶点的标记相同，就表示会构成环路。

### 最短路径算法

在给定的图存储结构中，从某一顶点到另一个顶点所经过的多条边称为路径。

最短路径不仅适用于无向加权图，也适用于有向加权图。

#### 迪杰斯特拉算法（Dijkstra）

寻找某个特定顶点到其它所有顶点的最短路径，该算法要求所有路径的权值为非负数。

#### 弗洛伊德算法（Floyd-Warshall）

寻找各个顶点之间的最短路径，允许非环路的路径权值为负数，该算法不仅适用于稀疏图，在稠密图（路径数量多的图）中寻找最短路径的效率也很高。

#### 贝尔曼福特算法（Bellman-Ford）

寻找某个特定顶点到其它所有顶点的最短路径，该算法允许路径的权值为负数。

#### 约翰逊算法（Johnson）

寻找各个顶点之间的最短路径，允许非环路的路径权值为负数，该算法更适用于稀疏图（路径数量少的图）。




