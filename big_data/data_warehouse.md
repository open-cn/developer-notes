## Data Warehouse

数据仓库是一个面向主题的（Subject Oriented）、集成的（Integrated）、相对稳定的（Non-Volatile）、反映历史变化的（Time Variant）数据集合。用于支持管理决策（Decision Making Support）。

从逻辑、概念层面来看数据仓库和数据库其实是一样的，它们都是通过某种数据库软件，基于某种数据模型来组织管理数据。

但是他们的侧重点不同：通常数据库更关注业务交易处理（OLTP）层面；而数据仓库关注数据分析（OLAP）层面。

| 数据库（DataBase）   | 数据仓库（Data Warehouse） |
| -------------------- | -------------------------- |
| 表结构相对复杂       | 表结构相对简单             |
| 存储结构相对紧凑     | 存储结构相对松散           |
| 较少数据冗余         | 较多数据冗余               |
| 一般读、写都有优化   | 一般只有读优化             |
| 相对简单的读、写查询 | 相对复杂的读查询           |
| 单次操作数据量较少   | 单次操作涉及数据量相对较大 |

数据库一般都会追求响应速度、数据的一致性等特点。所以我们在设计数据库模型上一般都会遵循一些范式，比如1NF、2NF、3NF等。目的都是为了减少数据的冗余和相应速度等。

而数据仓库强调的是数据分析的效率，复杂查询的响应速度和数据之间的相关性之类的分析。所以，数据仓库一般都是多维模型，有较多的数据冗余，但是同时查询的效率也会提高。从某种意义上来说，数据仓库就是反范式设计的数据库。


建立数据仓库最重要的目的就是要把事务处理与数据分析解耦合，增加系统的可拓展性。

数据仓库就是为了业务处理和数据分析解耦的。如果我们不解耦合，也就是我们的数据分析直接来自业务库，导致在数据分析的时候存在几个问题。

**结构复杂、大规模查询慢**

业务库一般是针对业务专门设计的，为了减少数据冗余，会遵循3NF范式。这就导致表之间的关系其实是一张网，通过外键、主键之类的进行关联。我们很多的业务表信息都是一堆编码，通过编码去关联详情。

此时如果对于一些数据分析涉及到具体详情信息，我们可能需要通过多层关联才能得到，这就给分析数据增加很大的复杂度。

此时如果每个表都是大表，数据量都很大，那么我们就可以带薪蹲坑了（编码一分钟，执行九分钟）。

如果在同一个数据库还能勉强做，如果数据满天星，mysql、mongo、hdfs哪里都有的话，老实说这个时候做关联操作实在是有心无力。


**脏数据乱入**

业务库一般存储了所有的业务数据，与此同时，在业务过程中可能由于各种原因比如网络、宕机、数据校验不完善等原因，会产生一些列脏数据。

脏数据包括但不限于以下情况：

脏数据情况  | 案例
---|---
核心数据为空 | uid、odrId为null
数据不合法   |手机号码、身份证、日期之类的不符合规范
数据错误 |   比如在线时长、登陆时长超过合理值
数据重复 |   数据重复上报

如果我们在做数据分析的时候还得对于所有的脏数据再处理一次，那这效率。

如果拿数据支持管理决策，一不小心因为处理脏数据不完善，搞个错误数据，误了公司决策，这个锅你背得动吗？


**无法反应历史**

业务库一般的不会存储很长历史的数据以保证响应速度，这样对于我们需要做一个历史衍变、趋势之类的数据分析，单靠业务库就已经很难实现了。

而历史趋势对于我们后续的决策是很有借鉴意义。比如营收，销量之类的做个历史分析

### 建立数仓

在数据仓库中，我们数据的设计模型一般采用星型结构。主要有两部分组成：事实表、维度表.

**事实表**

处于星星结构的中心，存储某种业务各个维度的数据，其中各个维度一般都是对应编码。

比如订单表

**维度表**

维度表可以看作是事实表的发散表，对应着事实表里面的每一个维度。

分析数据的步骤就变成了下面模式化的步骤：

1. 选择分析主题(营收、登陆、时长等)
2. 找相关业务表（即营收事实表、登陆事实表、时间事实表等）
3. 根据分析数据需求确定维度（即确定事实表需要关联的维度表）
4. 计算结果(关联需要的维度后计算结果)

##### ETL
数据仓库一般都是通过etl一天更新一次。

在数据仓库中，我们对于模型在设计方面最基本的要求有几点：

- 数据字段类型统一：同一个含义的字段要类型一致（比如，登陆、消费都有用户id，要么都是int、要么都是string）。
- 命名要规范：采用驼峰或分隔要统一，切勿混用，不要出现usrId,musr_id同时出现的情况
- 相同含义的字段保持一致：比如手机号码,决定用msdn 就不要在出现phoneNumber 之类的
- 缺省值处理：对于缺省值或异常错误的数据要有默认值。方便分析的时候删选过滤。
- 字段命名可理解：不要乱七八糟乱取名字，便于理解的名字，最好维护一个英文缩写表。


脏数据对我们数据分析的影响很大，所以对于每一个业务，我们在etl的数据清洗过程中就对脏数据进行处理，同时把业务数据按照我们数据模型设计的规范导入到数据仓库。

##### 快速复杂查询

快速复杂查询不是说执行一个复杂的sql能够很快返回结果。而是我们通过建立合理、规范的数据仓库，使得原本在业务库需要通过各种关联才得到的结果在数据仓库中可以用过简单关联和计算就得到到结果。

单靠仓库本身的比如hive查询可能需要花费较长的时间，因为基于mapreduce，是硬伤，但是我们可以通过将构建多维查询比如通过kylin、druid、clickhouse等将所有的查询可能保存下来，达到秒级查询效率也是可以。



### ClickHouse
Yandex（俄罗斯的“百度”）在2016年6月15日开源了一个数据分析的数据库，名字叫做ClickHouse，这对保守俄罗斯人来说是个特大事。更让人惊讶的是，这个列式存储数据库的跑分要超过很多流行的商业MPP数据库软件，例如Vertica。如果你没有听过Vertica，那你一定听过 Michael Stonebraker，2014年图灵奖的获得者，PostgreSQL和Ingres发明者（Sybase和SQL Server都是继承 Ingres而来的）, Paradigm4和SciDB的创办者。Michael Stonebraker于2005年创办Vertica公司，后来该公司被HP收购，HP Vertica成为MPP列式存储商业数据库的高性能代表，Facebook就购买了Vertica数据用于用户行为分析。

ClickHouse实际上来源于内部的几个项目的整合，项目起源于2011年左右。到2013年的时候，ClickHouse的性能就和Vertica大致相同；2015年12月，ClickHouse的数量已经达到11万亿行，数据表有200多列，主集群的服务器数量也从初期的60台到394台。

最大的应用来自于Yandex的统计分析服务Yandex.Metrica，类似于 Google Analytics(GA)，帮助网站或移动应用进行数据分析和精细化运营工具，据称Yandex.Metrica为世界上第二大的网站分析平台。ClickHouse在这个应用中，部署了近四百台机器，每天支持200亿的事件和历史总记录超过13万亿条记录，这些记录都存有原始数据（非聚合数据），随时可以使用SQL查询和分析，生成用户报告。

简单的说，ClickHouse作为分析型数据库，有三大特点：一是跑分快， 二是功能多 ，三是文艺范

1. 跑分快： ClickHouse跑分是Vertica的5倍快：

    ClickHouse性能超过了市面上大部分的列式存储数据库，相比传统的数据ClickHouse要快100-1000X，ClickHouse还是有非常大的优势：

    100Million 数据集：ClickHouse比Vertica约快5倍，比Hive快279倍，比My SQL快801倍

    1Billion 数据集：ClickHouse比Vertica约快5倍，MySQL和Hive已经无法完成任务了


2. 功能多：ClickHouse支持数据统计分析各种场景
    + 支持类SQL查询，
    + 支持繁多库函数（例如IP转化，URL分析等，预估计算/HyperLoglog等）
    + 支持数组(Array)和嵌套数据结构(Nested Data Structure)
    + 支持数据库异地复制部署

3. 文艺范：目前ClickHouse的限制很多，生来就是为小资服务的
    + 目前只支持Ubuntu系统
    + 不提供设计和架构文档，设计很神秘的样子，只有开源的C++源码
    + 不理睬Hadoop生态，走自己的路

ClickHouse是一个面向联机分析处理(OLAP)的开源的面向列式存储的DBMS，简称CK, 与Hadoop, Spark相比，ClickHouse很轻量级。ClickHouse支持线性扩展，简单方便，高可靠性，高容错。


### Druid
### Kudu（+Impala）
### IndexR
### 华为Carbondata
### 腾讯Hermes
### 沈阳延云YDB





